# ğŸš€ CC-LTMR â€“ Character-Conditioned Long-Term Memory Reasoner

**CC-LTMR** is an AI-powered application that checks whether a given character backstory is *consistent* or *contradictory* with extremely long novels using:

* Long-term vector memory
* Character-specific episodic memory
* Hierarchical memory compression
* Gemini reasoning model

---

## âœ¨ Key Features

* ğŸ” **Long-Context Understanding** â€“ Handles books with 100k+ tokens
* ğŸ§  **Character-Specific Memory** â€“ Each character gets their own memory profile
* ğŸ—‚ **Hierarchical Episodic Slots** â€“ Compresses global memory efficiently
* ğŸ¤– **Gemini-Powered Reasoning** â€“ Produces clean `0/1` predictions with rationale
* â™»ï¸ **Resumable Pipeline** â€“ Safe for long-running batch inference
* ğŸ“„ **Submission-Ready Output** â€“ Exports clean `final_predictions.csv`

---

## ğŸ“ Project Structure

```
cc-ltmr/
 â”œâ”€â”€ app/                 # AI Studio frontend app
 â”œâ”€â”€ downloaded_dataset/  # Auto-downloaded books + test.csv
 â”œâ”€â”€ pipeline.py         # Pathway end-to-end pipeline
 â”œâ”€â”€ final_predictions.csv
 â””â”€â”€ .env.local
```

---

## âš™ï¸ Local Setup

### **Prerequisites**

* Node.js 18+
* Python 3.10+

---

## â–¶ï¸ Run the App Locally

### 1ï¸âƒ£ Install Dependencies

```bash
npm install
```

---

### 2ï¸âƒ£ Configure Gemini API Key

Create a file called **.env.local** in the project root and add:

```
GEMINI_API_KEY=your_api_key_here
```

---

### 3ï¸âƒ£ Start the Development Server

```bash
npm run dev
```

Open browser at:

```
http://localhost:3000
```

---

## ğŸ“Š Output Format

After running the pipeline, predictions are saved in:

**final_predictions.csv**

| Story ID | Prediction | Rationale                                                                 |
| -------- | ---------- | ------------------------------------------------------------------------- |
| 46       | 1          | The backstory aligns with the novelâ€™s account of Thalcaveâ€™s displacement. |
| 137      | 0          | Faria was not re-arrested in 1815 as claimed.                             |

---

## ğŸ§  How It Works

* **Books are chunked & embedded** into a long-term memory store.
* **Character-conditioned retrieval** builds episodic memory for each character.
* **Hierarchical clustering** compresses memories into fixed-size slots.
* **Gemini reasoning model** judges consistency using retrieved evidence.

---

## ğŸ Ready for Hackathons

This system is optimized for:

* Low-data scenarios (â‰¤ 80 rows)
* Extremely long documents
* High-stakes consistency reasoning

---

## ğŸ“œ License

MIT License
